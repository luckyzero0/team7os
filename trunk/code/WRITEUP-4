#WRITEUP#

Writeup for Project 4, Spring2011
04/24/2011


Team 24:	Nick Bopp		nbopp@usc.edu

			Mihir Sheth		mihirshe@usc.edu

			James Cramer	jcramer@usc.edu


---USAGE---
To build coff2noff:
	gmake coff2noff (inside the bin directory)
	
To build Nachos:
	gmake (inside the network directory)
	
To build all the tests:
	make all (inside the test directory)
	make netOffice (inside the test directory)

To run the office (MUST USE 5 SERVERS!), instructions for fewer servers are found below:
	nachos -m 0 -o 1 (Server0)
	nachos -m 1 -o 1 (Server1)
	nachos -m 2 -o 1 (Server2)
	nachos -m 3 -o 1 (Server3)
	nachos -m 4 -o 1 (Server4)
	
	nachos -m 5 -x ../test/net10Cust (exec's 10 netCustomers)
	nachos -m 6 -x ../test/net10Cust (exec's 10 more netCustomers)
	nachos -m 7 -x ../test/netAPPM (execs 3 App Clerks, 3 Pic Clerks, 3 Passport Clerks, and 1 Manager)
	nachos -m 8 -x ../test/netCashSen (exec's 3 Senators, and 3 Cashier Clerks)


---DOCUMENTATION---

I. REQUIREMENTS

	Project 4 has two main components.  The first was to make each entity of the Passport Office a single threaded program which
	uses RPC's to share data and locking primitives with other entities.
	
	The second was to go from one server, to five fully redundant servers.  The client must randomly select which server to request from.
	That server must then forward the request to all the other servers.  Using the total ordering algorithm, all servers process all requests
	in the same order.

II. ASSUMPTIONS

	1. All servers process each request to maintain consistent state, but only the server that was originally contacted by the client
		sends a response message back.
		
	2. The number of servers is set at compile time, with the constant #define NUM_SERVERS in "system.h" in the threads directory.
		The tester must run exactly this many server processes for the application to function correctly. (Machines 0 - (NUM_SERVERS - 1)
		are the machine ID's for servers, which is used for broadcasting forwarded messages and timestamps).

III. DESIGN

	Parts 1/2:
		Our design follows the pattern set by Professor Crowley in the lecture.
		Main steps:
			1. Check the TLB for virtual page
			2. If not in the TLB, page fault.
			3. Check the IPT for the correct virtual page
				a. If it's there copy to the TLB and return.
				b. If it's not, look for an available physical page.
				c. If no physical pages are available, select a RANDOM or FIFO one to evict.
					i. Propagate dirty bit up from the TLB to the IPT.
					ii. If IPT page is dirty, write it to the swap file.
					iii. Update the page table for the evicted page.
				d. Read the needed virtual page into physical memory from the executable, swap file, or by bzero'ing.
			4. Copy the entry from the IPT to the TLB.
			5. Restart the user instruction.
			
	Part 3:
		We used Post as our abstraction for message sending, and did all the message handling on the server and client kernel code.
				No changes in any user program have to be made for RPCs to work.
		
		Since the current implementation of Locks/CVs cause threads to sleep, we had to create versions of these that did the same job but did not cause any thread to sleep.
		We created a version of CVs and Locks that are compatible with our networking design, named ServerCondition and ServerLock respectively.
		Server does all the work for Syscalls relating to CVs, Locks, or MVs. Clients always pass their current thread's ID when messaging the server.
		The server uniquely identifies a client thread from:
			a. The Client Address, stored in the PacketHeader when Send is called.
			b. The Thread ID which is stored in the message.
		Hence, servers send messages to the post box which corresponds to the desired thread's ID, and the thread itself only Receives on this mailbox.
		
		Main Steps:
			1. If userprog uses a syscall related to locks, condition variables or monitors, check whether networking is enabled. If not, continue using syscalls as in assignment 2.
			2. If it is, validate parameters and then send server a request to perform the syscall, passing along any needed information, and wait for a reply.
			3. Server constantly checks if it has received a message. If it has, handle one message a time:
				a. Find out what the client requested.
				b. Do what the client requested.
				c. If necessary, send an acknowledgement message back to the client.
			4. Upon receiving a message from the server, client finishes syscall, returning some value if needed.
	
!! IF YOU WANT TO CHANGE THE NUMBER OF SERVERS, YOU MUST CHANGE THE FOLLOWING: !!
	In the file: "threads/system.h", change:
		#define NUM_SERVERS 5
	to
		#define NUM_SERVERS (number of servers you desire)
!!!!!!

IV. IMPLEMENTATION

	Parts 1/2:
	+ Files Modified
		- exception.cc
		- addrspace.h/cc
		- system.cc
		
		- syscall.h
		- synch.h/cc
		- server.cc
	
	+ Files Added
		- test/* (All the tests in the test directory)
		- vm/ipt.h
		
	+ Data Structures Added
		Lock* iptLock;
		IPTEntry ipt[];
		
		
	+ Data Structures Modified
		Added Lock* pageTableLock to each AddrSpace.
		Changed class of pageTable to IPTEntry*.
			
	+ Functions Added
		- New syscalls
			. HandlePageFault()
			+ Supporting Subroutines
				- HandleIPTMiss()
				- UpdateTLB()
				- EvictPageFromTLB()
				- HandleFullMemory()
				
	Part 3:
	+ Files Modified
		- synch.h/cc
		- exception.cc
		- syscall.h
		- start.s
		- main.cc
		

	
	+ Files Added
		- server.cc
		
	+ Data Structures Added
	
		In server.cc:
			1. LockEntry - uses ServerLock instead of Lock
			2. ConditionEntry - uses ServerCondition instead of Condition
			3. MonitorEntry
			4. LockEntry serverLocks[MAX_LOCKS];
			5. ConditionEntry serverCVs[MAX_CONDITIONS];
			6. MonitorEntry serverMVs[MAX_MONITORS];
		
		In synch.h:
			1. ServerLock - differs from locks in the following ways:
				a) Ownership is checked via ints (clientID, threadID) instead of actual thread pointers. These are passed in the constructor.
				b) Thread does not fall asleep if it is trying to acquire a lock that has already been acquired. Instead, message is just not sent back to client. The client still has to wait for a message in the future.
			
			2. ServerCondition - differs from Conditions in the following ways:
				a) Takes in a ServerLock instead of a Lock
				b) Ownership is checked via ints (clientID, threadID) instead of actual thread pointers.
				c) Thread does not fall asleep when a CV calls Wait - just don't send a message to the client. 
				
			3. ClientThreadPair - struct which stores a ClientID, ThreadID pair.
				
		In exception.cc:
			1. char buffer[MaxMailSize] - character array which is sent as a packet across the network
		
	+ Data Structures Modified
		In synch.h/cc:
			1. ServerLocks are just modified versions of Locks
			2. ServerCondition are just modified version of Conditions.
			
			
	+ Functions Added
	
		In server.cc:
			1. void RunServer(void) - Causes the server to start.
			2. void handleIncomingRequests() - Constantly runs and handles client requests, one at a time. Calls the requested server-end syscall handle function.
			3. void parsePacket(char* serverBuffer) - Parses an incoming message. We chose each token to be seperated by the ',' character, and our endline character is "*"
			4. void initServerData() - Initializes server data
			5. Server-end syscall handle functions:
					a) LockID CreateLock_Syscall_Server(char* name)
					b) void Acquire_Syscall_Server(LockID id)
					c) void Release_Syscall_Server(LockID id
					d) void DestroyLock_Syscall_Server(LockID id)
					e) ConditionID CreateCondition_Syscall_Server(char* name)
					f) void Signal_Syscall_Server(ConditionID conditionID, LockID lockID)
					g) void Wait_Syscall_Server(ConditionID conditionID, LockID lockID)
					h) void Broadcast_Syscall_Server(ConditionID conditionID, LockID lockID)
					i) void DestroyCondition_Syscall_Server(ConditionID id)
					j) MonitorID CreateMonitor_Syscall_Server(char* name)
					k) int GetMonitor_Syscall_Server(MonitorID monitorID)
					l) void SetMonitor_Syscall_Server(MonitorID monitorID, int value)
			6. Helping sub-routines:
					a) int getAvailableServerLockID()
					b) void deleteServerLock(int id)
					c) int getAvailableServerMonitorID()
					d) int getAvailableServerConditionID()
					e) void deleteServerCondition(int id)
		
		In exception.cc:
			1. More syscalls:
				a) MonitorID CreateMonitor_Syscall(unsigned int vaddr, int len)
				b) GetMonitor_Syscall(MonitorID monitorID)
				c) SetMonitor_Syscall(MonitorID monitorID, int value)
		
V. TESTING

	+ How to Test
	
		See USAGE above.
		
		The .c's listed below are the tests.  For example, to build, just do "gmake forkTest".
		
		PARTS 1 AND 2: ----------------------------------------------------------------------
		
		As part one consists of just running the distributed passport office on one server,
		if you want to explicitly test part1, you'll need to redefine NUM_SERVERS in system.h
		and recompile.

		*NOTE: All of the below tests are meant to be run on a NachOS server. If you're unfamiliar, here's how to set it up:
		
		terminal1 (server):  nachos -m 0 -o 1 		
		terminal2 (client):  nachos -m 1 -x ../test/testName

		Create separate boxes for each client and each server.
										
		
				/* testLocks.c */
		/*	Recycled from projects 2 & 3. A Quick test program to check if lock 
		*	related SYSCALLS are working over the network.
		* 	Performs a few tests to check bad construction data, as well as
		* 	Passing bad lock IDs to demonstrate attempting to acquire non-owned
		* 	locks.
		* 	The final test demonstrates a small mutex scenario, in which the final
		* 	result of raceCondition should should be 0, 5, or 10, depending on which
		* 	thread runs first, but never any value in between.
		*/

				/*testConditions.c*/
		/*
		 * Tests CVs on the network. Attempt to pass bad construction data,
		 * as well as access CVs with bad parameters.
		 * If successfully, bad CVs are not created, and
		 * t2 will run before t1.
		 * Finally, tests broadcast. If successful, all threads will
		 * exit.
		 * NOTE: This test is not designed to work with -rs'ing.
		 */
		 
				/*testMonitors.c*/
		/*
		 * Small series of tests that demonstrate Monitor syscalls over
		 * the network. Creates, sets, and retrieves the value of a
		 * monitor variable.
		 */
		 
		 
				/*NetOffice*/
		/*
		 * Our main test was running the full PassPortOffice simulation,
		 * as it has been tested thoroughly in previous assignments and
		 * is known to work without issues. Here's how to set it up:
		 *     - in /test/, make netOffice
		 *     - in separate windows, in /network/, create 5 servers (nachos -m 0 -o 1, nachos -m 1 -o 1, etc)
		 *                *NOTE* Servers must have a NetworkID < NUM_SERVERS (which by default = 5)
		 *     - the client programs are listed below, run each in a separate terminal:
		 */

				/*net10Cust*/
		/*
		 * Creates 10 Customer processes on the network. 
		 * You will need to run this twice to ensure that
		 * 20 customers go through the passport office,
		 * otherwise the simulation will not complete.
		 */

				/*netAPPM*/
		/*
		 * Creates the Application, Picture, and Passport Clerk processes, and the
		 * manager.
		 */
		 
				/*netCashSen*/
		 /*
		  * Creates the Cashier and 3 Senator processes.
		  */
		  




VI. DISCUSSION

The only wierd issue we ran into was with backgrounding servers and clients (ex nachos -m 0 -o 1 & nachos -m 1 -o 1 etc), basically using one unix box for the 5 servers, and the other for the 4 client nachos. For some reason, running the simulation in this manner locks up with more than 4 servers, but works fine for 4 or less. However, running everything on separate boxes works just fine. Not really sure why.

VII. MISCELLANEOUS

Please feel free to contact us if you have any questions. We'd be happy to meet to meet up and discuss any issues/what's going on in our code.
Please contact us by emailing Nick Bopp at nbopp@usc.edu.


	



VII. MISCELLANEOUS

Please feel free to contact us if you have any questions. We'd be happy to meet to meet up and discuss any issues/what's going on in our code.
Please contact us by emailing Nick Bopp at nbopp@usc.edu.


	
